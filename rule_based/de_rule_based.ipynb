{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "629872f1",
   "metadata": {},
   "source": [
    "- ### This .ipynb is a rule based approach for extracting ERM-Components from unstructured text\n",
    "\n",
    "- ### Concept: \n",
    "    <img src=\"../pictures/workflow.png\" width=\"500\">\n",
    "    \n",
    "- ### Coding workflow:\n",
    "    1. Preprocessing\n",
    "        - Text cleaning\n",
    "        - Fault correction (levenshtein distance) --> optional\n",
    "    2. Structuring\n",
    "        - Generate Subject-Predicate-Object tuples\n",
    "        - Text Summarization (with term frequency-normalized) --> optional\n",
    "        - Extract keywords (with tf-idf) --> optional\n",
    "    3. Analysis\n",
    "        - Extraction of primary keys\n",
    "        - Extraction of attributes\n",
    "        - Extraction of ISA-Relation --> optional (limitations)\n",
    "        - Extraction of entities\n",
    "        - Extraction of relations\n",
    "        - Extraction of cardinalities\n",
    "    4. Transformation\n",
    "        - Generate .json output (to feed it into ER-Modeling Tool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac00c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spellchecker import SpellChecker\n",
    "from string import punctuation\n",
    "import random\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "from heapq import nlargest\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#### necessary pip installments ####\n",
    "# pip install spacy\n",
    "# pip install pyspellchecker\n",
    "# python -m spacy download de_core_news_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1ab0a2c",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "788b9f07",
   "metadata": {},
   "source": [
    "#### - Text cleaning (Step 1)\n",
    "\n",
    "- main goal: transform text data from input.txt to preprocessedData.json\n",
    "- the subfolder \"examples\" contains different ER-Diagram examples in unstructured text form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f0eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only text in \"Text:\"\n",
    "# delete whitespaces and consider also text in next line etc.\n",
    "\n",
    "input = \"../examples/input.txt\"\n",
    "with open(input, 'r') as file:\n",
    "    text = file.readlines()\n",
    "\n",
    "language_line_index = None\n",
    "for i, line in enumerate(text):\n",
    "    if \"Sprache:\" in line:\n",
    "        language_line_index = i\n",
    "        break\n",
    "    \n",
    "cleaned_lines = [line.strip() for line in text[:language_line_index]]\n",
    "\n",
    "\n",
    "single_line_text = ' '.join(cleaned_lines)\n",
    "\n",
    "for line in text[language_line_index:]:\n",
    "    single_line_text=single_line_text+\"\\n\"+line\n",
    "    \n",
    "lines = single_line_text.split('\\n')\n",
    "cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "data = {}\n",
    "for line in cleaned_lines:\n",
    "    key, value = line.strip().split(': ',1)\n",
    "    data[key] = value\n",
    "\n",
    "text = data.get('Text', [])\n",
    "data['Text'] = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "output = \"../rule_based/preprocessedData.json\"\n",
    "with open(output, 'w') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e9d366",
   "metadata": {},
   "source": [
    "#### - Text cleaning (Step 2)\n",
    "\n",
    "- find sentences in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bd7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find sentences with spacy model (small)\n",
    "# add new item to .json\n",
    "\n",
    "with open(output, 'r', encoding='UTF-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "text = data.get('Text', [])\n",
    "doc = nlp(text)\n",
    "sentences = [sent.text.strip() for sent in doc.sents]\n",
    "data[\"sentences\"] = sentences\n",
    "\n",
    "with open(output, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e003793",
   "metadata": {},
   "source": [
    "#### - Text cleaning (Step 3)\n",
    "\n",
    "- delete unneccessary sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d4585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences with these words in it should not be considered\n",
    "# these could be sentences for introduction of an exercise\n",
    "\n",
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "filtered_text_list = []\n",
    "for string in data[\"sentences\"]:\n",
    "    if not re.search(r\"(Datenbank|ER-Modell|ER|Entität|Datensatz|SQL|relational|Modellierung)\", string):\n",
    "        filtered_text_list.append(string)\n",
    "data[\"sentences_cleaned\"] = filtered_text_list\n",
    "\n",
    "with open(output, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f32267d3",
   "metadata": {},
   "source": [
    "#### - Fault Correction\n",
    "\n",
    "- pyspellchecker uses a Levenshtein Distance algorithm to find permutations within an edit distance of 1 from the original word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe6819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not consider the spelling mistakes because also correct words are changed to incorrect words\n",
    "\n",
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "spell = SpellChecker(language='de',distance=1) \n",
    "\n",
    "text = ' '.join(data.get('sentences_cleaned', []))\n",
    "doc = nlp(text)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "misspelled = spell.unknown(tokens)\n",
    "\n",
    "for word in misspelled:\n",
    "    if spell.correction(word)!=None:\n",
    "        tokens = [token.replace(word, spell.correction(word)) for token in tokens]\n",
    "        ## UNCOMMENT FOR VISUALIZATION ###\n",
    "        #print(word + \" ---ersetzt durch---> \" + spell.correction(word) + \" ---Liste---> \" + str(spell.candidates(word)))\n",
    "\n",
    "punctuation = punctuation + '\\n'\n",
    "text = ''.join(\" \" + token if token not in punctuation and i > 0 else token for i, token in enumerate(tokens))\n",
    "doc = nlp(text)\n",
    "sentences = [sent.text.strip() for sent in doc.sents]  \n",
    "data['sentences_corrected'] = sentences\n",
    "\n",
    "with open(output, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d85b490b",
   "metadata": {},
   "source": [
    "### 2. Structuring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bfa85cd",
   "metadata": {},
   "source": [
    "#### - Term frequency - normalized (could be used for text-summerization)\n",
    "Formula: \n",
    "\n",
    "<img src=\"../pictures/tf.png\" width=\"500\">\n",
    "\n",
    "Concept:\n",
    "1. Count occurrences per word in the text (stop words excluded)\n",
    "2. Calculate weight per used word\n",
    "3. Calculate sentence weight by summarizing weight per word\n",
    "4. Find sentences with the highest weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24400337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Geschäft': 1, 'Filialen': 3, 'Filiale': 6, 'höchstens': 3, 'Filialleiter': 4, 'geführt': 1, 'leiten': 1, 'bestimmt': 1, 'bietet': 1, 'Produkte': 2, 'Produkt': 2, 'angeboten': 1, 'beschäftigt': 1, 'Mitarbeiter': 4, 'Verkauf': 3, 'bearbeiten': 1, 'involviert': 1, 'Jedes': 1, 'enthält': 2, 'Preis': 1, 'Produktname': 1, 'eindeutige': 1, 'Produkt-ID': 1, 'spezielle': 1, 'Produkttypen': 1, 'Neuwaren': 1, 'Verpackungsnummer': 1, 'registriert': 1, 'Gebrauchtwaren': 1, 'Anzahl': 1, 'Vorbesitzer': 1, 'mitgeführt': 1, 'Filial-ID': 1, 'eindeutig': 1, 'identifiziert': 2, 'Filialnamen': 1, 'Filialadresse': 1, 'Telefonnummer': 2, 'Datum': 1, 'Uhrzeit': 1, 'Betrag': 1, 'Mitarbeiternamen': 1, 'bestehend': 1, 'Vorname': 1, 'Nachname': 1, 'mehrere': 1, 'Mitarbeiteradressen': 1, 'ID': 1}\n",
      "{'Geschäft': 0.16666666666666666, 'Filialen': 0.5, 'Filiale': 1.0, 'höchstens': 0.5, 'Filialleiter': 0.6666666666666666, 'geführt': 0.16666666666666666, 'leiten': 0.16666666666666666, 'bestimmt': 0.16666666666666666, 'bietet': 0.16666666666666666, 'Produkte': 0.3333333333333333, 'Produkt': 0.3333333333333333, 'angeboten': 0.16666666666666666, 'beschäftigt': 0.16666666666666666, 'Mitarbeiter': 0.6666666666666666, 'Verkauf': 0.5, 'bearbeiten': 0.16666666666666666, 'involviert': 0.16666666666666666, 'Jedes': 0.16666666666666666, 'enthält': 0.3333333333333333, 'Preis': 0.16666666666666666, 'Produktname': 0.16666666666666666, 'eindeutige': 0.16666666666666666, 'Produkt-ID': 0.16666666666666666, 'spezielle': 0.16666666666666666, 'Produkttypen': 0.16666666666666666, 'Neuwaren': 0.16666666666666666, 'Verpackungsnummer': 0.16666666666666666, 'registriert': 0.16666666666666666, 'Gebrauchtwaren': 0.16666666666666666, 'Anzahl': 0.16666666666666666, 'Vorbesitzer': 0.16666666666666666, 'mitgeführt': 0.16666666666666666, 'Filial-ID': 0.16666666666666666, 'eindeutig': 0.16666666666666666, 'identifiziert': 0.3333333333333333, 'Filialnamen': 0.16666666666666666, 'Filialadresse': 0.16666666666666666, 'Telefonnummer': 0.3333333333333333, 'Datum': 0.16666666666666666, 'Uhrzeit': 0.16666666666666666, 'Betrag': 0.16666666666666666, 'Mitarbeiternamen': 0.16666666666666666, 'bestehend': 0.16666666666666666, 'Vorname': 0.16666666666666666, 'Nachname': 0.16666666666666666, 'mehrere': 0.16666666666666666, 'Mitarbeiteradressen': 0.16666666666666666, 'ID': 0.16666666666666666}\n",
      "{Jede Filiale darf von höchstens einem Filialleiter geführt werden.: 0.6666666666666666, Ein Filialleiter darf höchstens zwei Filialen leiten.: 0.6666666666666666, Ohne eine Filiale wird kein Filialleiter bestimmt.: 0.16666666666666666, Die Filiale bietet viele Produkte an.: 0.16666666666666666, Das Produkt wird von vielen Filialen angeboten.: 0.16666666666666666, Die Filiale beschäftigt viele Mitarbeiter.: 0.16666666666666666, Ein Mitarbeiter darf höchstens einen Verkauf bearbeiten.: 0.6666666666666666, Im Verkauf können viele Produkte involviert sein.: 0.16666666666666666, Jedes Produkt enthält Preis, Produktname und eindeutige Produkt-ID.: 0.5, Es gibt zwei spezielle Produkttypen: Neuwaren, bei denen die Verpackungsnummer registriert ist.: 0.3333333333333333, Bei Gebrauchtwaren wird die Anzahl der Vorbesitzer mitgeführt.: 0.16666666666666666, Eine Filiale wird durch die Filial-ID eindeutig identifiziert.: 0.5, Verkauf enthält Datum, Uhrzeit und Betrag.: 0.3333333333333333, Jeder Mitarbeiter hat einen Mitarbeiternamen bestehend aus Vorname und Nachname, eine oder mehrere Mitarbeiteradressen und eine Telefonnummer.: 0.3333333333333333, Die Mitarbeiter und der Filialleiter werden durch eine ID identifiziert.: 0.3333333333333333}\n",
      "5=17*0.3\n",
      "[Jede Filiale darf von höchstens einem Filialleiter geführt werden., Ein Filialleiter darf höchstens zwei Filialen leiten., Ein Mitarbeiter darf höchstens einen Verkauf bearbeiten., Jedes Produkt enthält Preis, Produktname und eindeutige Produkt-ID., Eine Filiale wird durch die Filial-ID eindeutig identifiziert.]\n",
      "['Jede Filiale darf von höchstens einem Filialleiter geführt werden.', 'Ein Filialleiter darf höchstens zwei Filialen leiten.', 'Ein Mitarbeiter darf höchstens einen Verkauf bearbeiten.', 'Jedes Produkt enthält Preis, Produktname und eindeutige Produkt-ID.', 'Eine Filiale wird durch die Filial-ID eindeutig identifiziert.']\n"
     ]
    }
   ],
   "source": [
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "# summerize only when more than tree sentences\n",
    "if len(data[\"sentences_cleaned\"]) > 3:\n",
    "    # lower summerization factor when more than 15 sentences\n",
    "    if len(data[\"sentences_cleaned\"]) > 15:\n",
    "        factor=0.3\n",
    "    else:\n",
    "        factor=0.5\n",
    "    text = ' '.join(data.get('sentences_cleaned', []))\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    print(word_frequencies)\n",
    "\n",
    "    max_frequency = max(word_frequencies.values())\n",
    "    max_frequency\n",
    "\n",
    "    # normalize frequency with maximal frequency\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word]/max_frequency\n",
    "    print(word_frequencies)\n",
    "\n",
    "    sentence_tokens = [sent for sent in doc.sents]\n",
    "\n",
    "    # count sentence frequency (sum of word frequency)\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word.text.lower()]              \n",
    "    print(sentence_scores)\n",
    "\n",
    "    # maximal number of sentences for summerization\n",
    "    select_length = int(len(sentence_tokens)*factor)\n",
    "    print(str(select_length)+\"=\"+str(len(sentence_tokens))+\"*\"+str(factor))\n",
    "    \n",
    "    # select most important sentences with highest sentence scores\n",
    "    summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)\n",
    "    print(summary)\n",
    "\n",
    "    final_summary = [word.text for word in summary]\n",
    "    data['text_summerized'] = final_summary\n",
    "    print(final_summary)\n",
    "\n",
    "\n",
    "with open(output, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4d6343d",
   "metadata": {},
   "source": [
    "#### - Term frequency - idf (could be used for keyword extraction)\n",
    "\n",
    "- could be useful to identify entities later\n",
    "- function TfidfVectorizer() is used for idf calculation\n",
    "\n",
    "Formula: \n",
    "\n",
    "<img src=\"../pictures/idf2.png\" width=\"500\">\n",
    "<img src=\"../pictures/idf1.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06b26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate collection.json \n",
    "# includes all input.txt\n",
    "# used as document collection\n",
    "\n",
    "def create_json_from_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.readlines()\n",
    "\n",
    "    language_line_index = None\n",
    "    for i, line in enumerate(text):\n",
    "        if \"Sprache:\" in line:\n",
    "            language_line_index = i\n",
    "            break\n",
    "\n",
    "    cleaned_lines = [line.strip() for line in text[:language_line_index]]\n",
    "    single_line_text = ' '.join(cleaned_lines)\n",
    "\n",
    "    for line in text[language_line_index:]:\n",
    "        single_line_text = single_line_text + \"\\n\" + line\n",
    "\n",
    "    lines = single_line_text.split('\\n')\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    data = {}\n",
    "    for line in cleaned_lines:\n",
    "        key, value = line.strip().split(': ', 1)\n",
    "        data[key] = value\n",
    "\n",
    "    text = data.get('Text', [])\n",
    "    data['Text'] = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "folder_path = \"../examples\"\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "all_data = []\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith(\".txt\"): \n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        json_data = create_json_from_text_file(file_path)\n",
    "        all_data.append(json_data)\n",
    "\n",
    "output_collection = \"../rule_based/collection.json\"\n",
    "with open(output_collection, 'w') as file:\n",
    "    json.dump(all_data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc7cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get keywords with \"inverted document frequency\" for each input text\n",
    "# saved in collection.json\n",
    "\n",
    "with open(output_collection, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "docs=[]\n",
    "for item in data:\n",
    "    docs.append(item.get('Text', []))\n",
    "# german vowels --> limitation (siehe collection.json)\n",
    "tv = TfidfVectorizer()\n",
    "t_vec = tv.fit_transform(docs)\n",
    "\n",
    "for doc_id in range(0,len(docs)):\n",
    "    my_list = []\n",
    "    for i in range(0,t_vec.shape[1]):\n",
    "        # dont consider numbers\n",
    "        if t_vec[doc_id,i] and not tv.get_feature_names_out()[i].isnumeric():\n",
    "            my_list.append({\"Wort\": tv.get_feature_names_out()[i], \"Gewicht\" : t_vec[doc_id,i]})\n",
    "    my_list = sorted(my_list, key=lambda x: -x[\"Gewicht\"])\n",
    "    # only the three most important keywords\n",
    "    data[doc_id]['keywords']=my_list[:3]\n",
    "\n",
    "with open(output_collection, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d43aa76",
   "metadata": {},
   "source": [
    "#### - Generate Subject-Verb-Object tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca96bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"6af27e582227439dae8093d4902e12a9-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Geschäft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">hat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">viele</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Filialen.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6af27e582227439dae8093d4902e12a9-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6af27e582227439dae8093d4902e12a9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6af27e582227439dae8093d4902e12a9-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6af27e582227439dae8093d4902e12a9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6af27e582227439dae8093d4902e12a9-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6af27e582227439dae8093d4902e12a9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6af27e582227439dae8093d4902e12a9-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6af27e582227439dae8093d4902e12a9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Ein Geschäft hat viele Filialen.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28a27fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spo sentences\n",
    "# saved in preprocessedData.json\n",
    "\n",
    "def s_p_o(doc):\n",
    "    res = []\n",
    "    for verb in [d for d in doc if d.pos_ == \"VERB\"]:\n",
    "        sb = [c.lemma_ for c in verb.children if c.dep_ == \"sb\"]\n",
    "        ob = [c.lemma_ for c in verb.children if c.dep_ == \"oa\"]\n",
    "        if len(sb) == 1 and len(ob) == 1:\n",
    "            res.append([sb[0], verb, ob[0]])\n",
    "    return res\n",
    "\n",
    "output = \"../rule_based/preprocessedData.json\"\n",
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "svo_list = []\n",
    "text = data.get('sentences_cleaned', [])\n",
    "for sent in text:\n",
    "    doc = nlp(sent)\n",
    "    svo = s_p_o(doc)\n",
    "    if len(svo)==1:\n",
    "        text = svo[0][0] + ''.join(\" \" + str(token) for token in svo[0][1:])  \n",
    "        svo_list.append(text)\n",
    "\n",
    "\n",
    "data['text_spo'] = svo_list\n",
    "\n",
    "with open(output, \"w\") as file:\n",
    "    json.dump(data, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe397345",
   "metadata": {},
   "source": [
    "### 3. Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03a0b3d5",
   "metadata": {},
   "source": [
    "#### - Extraction of primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d653cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"3df892db5196434d8da2872e1f77ff15-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Jedes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Produkt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">enthält</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Preis,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Produktname</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">und</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">eindeutige</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Produkt-ID.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3df892db5196434d8da2872e1f77ff15-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3df892db5196434d8da2872e1f77ff15-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Jedes Produkt enthält Preis, Produktname und eindeutige Produkt-ID.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c8977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['produkt-id', 'filial-id']\n"
     ]
    }
   ],
   "source": [
    "# get all nouns and than filter prim keys\n",
    "# prim keys: ...-ID or ...-Nummer --> limitation\n",
    "\n",
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "sentences = data[\"sentences_cleaned\"]\n",
    "nouns_list = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "    nouns_list.extend(nouns)\n",
    "\n",
    "nouns_list_lower = [word.lower() for word in nouns_list]\n",
    "filtered_nouns_list = [word for word in nouns_list_lower if re.search(r'\\b-id\\b', word) or re.search(r'\\b-nr\\b', word)]\n",
    "word_to_remove = \"id\"\n",
    "filtered_pk_list = [word for word in filtered_nouns_list if word != word_to_remove]\n",
    "print(filtered_pk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0647eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Produkt-ID', 'Filial-ID']\n"
     ]
    }
   ],
   "source": [
    "# if sentence contains only the word \"eindeutig\" than the last noun should be prim key with \"noun-ID\"\n",
    "\n",
    "result_list = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_noun = None\n",
    "    for token in doc:\n",
    "        if \"eindeutig\" in token.text.lower():\n",
    "            for token in reversed(doc):\n",
    "                    if token.pos_ == \"NOUN\":\n",
    "                        found_noun = token.text\n",
    "                        break\n",
    "    \n",
    "    if found_noun:\n",
    "        if \"-ID\" not in found_noun:\n",
    "            result_list.append(found_noun + \"-ID\")\n",
    "        else:\n",
    "             result_list.append(found_noun)\n",
    "             \n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a320ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filialleiter-ID', 'Mitarbeiter-ID']\n"
     ]
    }
   ],
   "source": [
    "# when only the words \"ID\" or \"id\" occur --> \"noun-ID\"\n",
    "\n",
    "result_list1 = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_nouns = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() == \"id\":\n",
    "            for token in reversed(doc):\n",
    "                if token.pos_ == \"NOUN\" and token.text.lower() != \"id\" and token.text not in found_nouns:\n",
    "                    found_nouns.append(token.text)\n",
    "\n",
    "result_list1.extend([noun + \"-ID\" for noun in found_nouns])      \n",
    "print(result_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883e4994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filialleiter-id', 'filial-id', 'mitarbeiter-id', 'produkt-id']\n"
     ]
    }
   ],
   "source": [
    "# final pk list\n",
    "final_pk = filtered_pk_list + result_list + result_list1\n",
    "lowercase_word_list = [word.lower() for word in final_pk]\n",
    "# delete duplicate with set()\n",
    "final_pk = list(set(lowercase_word_list))\n",
    "print(final_pk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eed91ba5",
   "metadata": {},
   "source": [
    "#### - Extraction of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ed3faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preis', 'produktname', 'anzahl', 'vorbesitzer', 'filialnamen', 'filialadresse', 'telefonnummer', 'datum', 'uhrzeit', 'betrag', 'mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer', 'filialleiter']\n",
      "[['produkt', ['preis', 'produktname']], ['gebrauchtwaren', ['anzahl', 'vorbesitzer']], ['filiale', ['filialnamen', 'filialadresse', 'telefonnummer']], ['verkauf', ['datum', 'uhrzeit', 'betrag']], ['mitarbeiter', ['mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer']], ['mitarbeiter', ['filialleiter']]]\n"
     ]
    }
   ],
   "source": [
    "# if more then two nouns in sentence: first=entity, other=attributes\n",
    "\n",
    "prefinal_attr_list = []\n",
    "attr_list = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_nouns = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            found_nouns.append(token.text.lower())\n",
    "\n",
    "    if len(found_nouns)>2:\n",
    "        prefinal_attr_list.append([found_nouns[0],found_nouns[1:]])\n",
    "        attr_list.extend(found_nouns[1:])\n",
    "\n",
    "#print(prefinal_attr_list)\n",
    "\n",
    "final_attr_list = [word for word in attr_list if '-id' not in word and 'id' != word]\n",
    "print(final_attr_list)\n",
    "\n",
    "def remove_id_words(lst):\n",
    "    new_list = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            new_sublist = [subitem for subitem in item[1] if not ('id' in subitem or '-id' in subitem)]\n",
    "            new_list.append([item[0], new_sublist])\n",
    "    return new_list\n",
    "\n",
    "final_attr_list_ents = remove_id_words(prefinal_attr_list)\n",
    "print(final_attr_list_ents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fafbde8",
   "metadata": {},
   "source": [
    "#### - Extraction of ISA-Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "768b8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# if sentence contains following verbs than it is a generalization\n",
    "\n",
    "isa_list1 = []\n",
    "target_verbs = [\"einbeziehen\", \"bestehen\", \"umfassen\", \"teilen\", \"beinhalten\"]\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_verbs = set()\n",
    "    for token in doc:\n",
    "        if token.lemma_ in target_verbs:\n",
    "            found_verbs.add(token.lemma_)\n",
    "    if found_verbs:\n",
    "        found_nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "        isa_list1.extend(found_nouns)\n",
    "\n",
    "# make distinct\n",
    "isa_list1 = list(set(isa_list1))\n",
    "\n",
    "print(isa_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d8a213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# sentence contain \"typ\" as word (noun) --> limitation: order can be different, maybe two splitted sentences etc.\n",
    "\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_nouns = []\n",
    "    isa_list2 = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() == \"typ\":\n",
    "            for token in doc:\n",
    "                if token.pos_ == \"NOUN\":\n",
    "                    found_nouns.append(token.text)\n",
    "            for token in doc:\n",
    "                if token.pos_ == \"NOUN\" and token.text != found_nouns[0]:\n",
    "                    isa_list2.append(token.text)\n",
    "\n",
    "print(isa_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc19aca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "final_isa_list = []\n",
    "final_isa_list.extend(isa_list1)\n",
    "final_isa_list.extend(isa_list2)\n",
    "print(final_isa_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c93f26d2",
   "metadata": {},
   "source": [
    "#### - Extraction of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6004147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['verkauf', 'preis', 'mitarbeiter', 'datum', 'filiale', 'geschäft', 'filialnamen', 'produkt']\n",
      "['preis', 'produktname', 'anzahl', 'vorbesitzer', 'filialnamen', 'filialadresse', 'telefonnummer', 'datum', 'uhrzeit', 'betrag', 'mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer', 'filialleiter', 'filialleiter-id', 'filial-id', 'mitarbeiter-id', 'produkt-id']\n",
      "['verkauf', 'mitarbeiter', 'filiale', 'geschäft', 'produkt']\n"
     ]
    }
   ],
   "source": [
    "# filtern aus svo list wenn in den vorherigen beiden lsiten das wort drin ist\n",
    "with open(output, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "spo = data[\"text_spo\"]\n",
    "first_last_words = []\n",
    "for sentence in spo:\n",
    "    doc = nlp(sentence)\n",
    "    first_word = doc[0].text.lower()\n",
    "    last_word = doc[-1].text.lower()\n",
    "    first_last_words.append(first_word)\n",
    "    first_last_words.append(last_word)\n",
    "\n",
    "unique_first_last_words = list(set(first_last_words))\n",
    "\n",
    "print(unique_first_last_words)\n",
    "\n",
    "# limitation: alle attribute müssen verschieden heißen: zwei mal name geht nicht \n",
    "# diese ents - att&pk_list = nur_ents_diese_list\n",
    "att_pk_list = []\n",
    "att_pk_list.extend(final_attr_list)\n",
    "att_pk_list.extend(final_pk)\n",
    "print(att_pk_list)\n",
    "\n",
    "final_ents =[]\n",
    "final_ents = [word for word in unique_first_last_words if word not in att_pk_list]\n",
    "print(final_ents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65c136cc",
   "metadata": {},
   "source": [
    "#### - Extraction of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b94786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['geschäft', 'hat', 'filiale'], ['filiale', 'bietet', 'produkt'], ['filiale', 'beschäftigt', 'mitarbeiter']]\n"
     ]
    }
   ],
   "source": [
    "# relations from spo sentences\n",
    "relations = []\n",
    "for sentence in spo:\n",
    "    doc = nlp(sentence)\n",
    "    if doc[0].text.lower() in final_ents and doc[-1].text.lower() in final_ents:\n",
    "        relations.append([doc[0].text.lower(),doc[1].text, doc[-1].text.lower()])\n",
    "\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c2859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"c2f3e4ae4e764f8a9934eeb8b280b34b-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Im</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Verkauf</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">können</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">viele</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Produkte</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">involviert</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">sein.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-5\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2f3e4ae4e764f8a9934eeb8b280b34b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Im Verkauf können viele Produkte involviert sein.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50e1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['geschäft', 'hat', 'filiale'], ['filiale', 'bietet', 'produkt'], ['filiale', 'beschäftigt', 'mitarbeiter'], ['mitarbeiter', 'bearbeiten', 'verkauf'], ['verkauf', 'involviert', 'produkt'], ['produkttype', 'registriert', 'verpackungsnummer']]\n"
     ]
    }
   ],
   "source": [
    "# if one sentence has two nouns (no attribute or ISA-beziehung or primary keys) and one verb than the verb can be a relation\n",
    "\n",
    "relations2 = []\n",
    "save_found_noun_pairs = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    found_nouns = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            found_nouns.append(token.lemma_.lower())\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb = token.text\n",
    "    if len(found_nouns)==2:\n",
    "        if all(word not in final_attr_list and word not in final_isa_list and word not in final_pk for word in found_nouns):\n",
    "            if found_nouns not in save_found_noun_pairs:\n",
    "                save_found_noun_pairs.append(found_nouns)\n",
    "                save_found_noun_pairs.append([found_nouns[1],found_nouns[0]])\n",
    "                relations2.append([found_nouns[0],verb,found_nouns[1]])\n",
    "\n",
    "print(relations2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5547c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['geschäft', 'hat', 'filiale'], ['filiale', 'bietet', 'produkt'], ['filiale', 'beschäftigt', 'mitarbeiter'], ['mitarbeiter', 'bearbeiten', 'verkauf'], ['verkauf', 'involviert', 'produkt'], ['produkttype', 'registriert', 'verpackungsnummer']]\n"
     ]
    }
   ],
   "source": [
    "relations2.extend(relations)\n",
    "\n",
    "final_beziehungen = []\n",
    "for sublist in relations2:\n",
    "    if sublist not in final_beziehungen:\n",
    "        final_beziehungen.append(sublist)\n",
    "\n",
    "print(final_beziehungen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d76b98",
   "metadata": {},
   "source": [
    "#### - Extraction of cardinalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "556556f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"246d80101d9e440289b5efa2863bfd38-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Geschäft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">hat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">viele</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Filialen.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-246d80101d9e440289b5efa2863bfd38-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-246d80101d9e440289b5efa2863bfd38-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-246d80101d9e440289b5efa2863bfd38-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-246d80101d9e440289b5efa2863bfd38-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-246d80101d9e440289b5efa2863bfd38-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-246d80101d9e440289b5efa2863bfd38-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-246d80101d9e440289b5efa2863bfd38-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-246d80101d9e440289b5efa2863bfd38-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Ein Geschäft hat viele Filialen.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ac1996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"6fe80bf503ed4c51994e507c0e339650-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Jede</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Filiale</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">darf</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">von</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">höchstens</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">einem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Filialleiter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">geführt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">werden.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sbp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-5\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6fe80bf503ed4c51994e507c0e339650-0-7\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6fe80bf503ed4c51994e507c0e339650-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Jede Filiale darf von höchstens einem Filialleiter geführt werden.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89121a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"d897ec7cdf6b4fdc90d1adaa51bf4551-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Im</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Verkauf</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">können</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">viele</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Produkte</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">involviert</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">sein.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-1\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-5\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d897ec7cdf6b4fdc90d1adaa51bf4551-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Im Verkauf können viele Produkte involviert sein.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee6b75f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['geschäft', 'hat', 'filiale'], 0], [['filiale', 'bietet', 'produkt'], 4], [['filiale', 'beschäftigt', 'mitarbeiter'], 6], [['mitarbeiter', 'bearbeiten', 'verkauf'], 7], [['verkauf', 'involviert', 'produkt'], 8], [['produkttype', 'registriert', 'verpackungsnummer'], 10]]\n"
     ]
    }
   ],
   "source": [
    "# get indices for each spo\n",
    "def find_matching_sentence(teilliste, saetze):\n",
    "    for i, satz in enumerate(saetze):\n",
    "        if all(wort in satz.lower() for wort in teilliste):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "index_list=[]\n",
    "for teilliste in final_beziehungen:\n",
    "    index = find_matching_sentence(teilliste, sentences)\n",
    "    if index is not None:\n",
    "        index_list.append([teilliste,index])\n",
    "\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c46fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 'Geschäft', None, 'Ein', 1, 1), (0, 'Filialen', 'hat', 'viele', 1, 'n')], [(4, 'Filiale', None, 'Die', 'n', 'm'), (4, 'Produkte', 'bietet', 'viele', 1, 'n')], [(6, 'Filiale', None, 'Die', 'n', 'm'), (6, 'Mitarbeiter', 'beschäftigt', 'viele', 1, 'n')], [(7, 'Mitarbeiter', None, 'Ein', 1, 1), (7, 'Verkauf', 'höchstens', 'einen', 0, 1)], [(8, 'Im', 'Im', 'Verkauf', 'n', 'm'), (8, 'Produkte', 'können', 'viele', 1, 'n')], [(10, 'Produkttypen', 'gibt', 'zwei', 'n', 'm'), (10, 'Produkttypen', 'zwei', 'spezielle', 'n', 'm'), (10, 'bei', 'bei', 'denen', 'n', 'm'), (10, 'Verpackungsnummer', 'denen', 'die', 'n', 'm')]]\n"
     ]
    }
   ],
   "source": [
    "# convert det to min max cardinality\n",
    "\n",
    "def get_determiners_for_noun(index):\n",
    "    doc = nlp(sentences[index])\n",
    "    noun_det_pairs = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == \"nk\": \n",
    "            noun = token.head.text \n",
    "            det = token.text\n",
    "            prev_word = doc[i-1].text if i > 0 else None\n",
    "            min_val, max_val = convert_det_to_min_max(det, prev_word)\n",
    "            noun_det_pairs.append((index, noun, prev_word, det, min_val, max_val))\n",
    "    return noun_det_pairs\n",
    "\n",
    "def convert_det_to_min_max(det, prev_word):\n",
    "    if \"mindestens\" == prev_word:\n",
    "        return 1, \"n\"\n",
    "    elif \"höchstens\" == prev_word:\n",
    "        return 0, 1\n",
    "    elif \"ein\" in det.lower():\n",
    "        return 1, 1\n",
    "    elif \"viele\" in det.lower():\n",
    "        return 1, \"n\"\n",
    "    elif \"jede\" in det.lower():\n",
    "        return 1, 1\n",
    "    elif \"genau\" in det.lower():\n",
    "        return 1, 1\n",
    "    else:\n",
    "        return \"n\", \"m\"\n",
    "    \n",
    "result_cardinality = []\n",
    "for item in index_list:\n",
    "    index = item[1]\n",
    "    result = get_determiners_for_noun(index)\n",
    "    result_cardinality.append(result)\n",
    "\n",
    "print(result_cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58ab5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Geschäft', None, 'Ein', 1, 'n'), (0, 'Filialen', 'hat', 'viele', 1, 1), (4, 'Filiale', None, 'Die', 1, 'n'), (4, 'Produkte', 'bietet', 'viele', 'n', 'm'), (6, 'Filiale', None, 'Die', 1, 'n'), (6, 'Mitarbeiter', 'beschäftigt', 'viele', 'n', 'm'), (7, 'Mitarbeiter', None, 'Ein', 0, 1), (7, 'Verkauf', 'höchstens', 'einen', 1, 1), (8, 'Im', 'Im', 'Verkauf', 1, 'n'), (8, 'Produkte', 'können', 'viele', 'n', 'm')]\n"
     ]
    }
   ],
   "source": [
    "# change the cardinality for each entity with the corresponding entity for correct min max notation\n",
    "\n",
    "def tausche_elemente(liste):\n",
    "    newlist=[]\n",
    "    index_count = {}\n",
    "    for tupel in liste:\n",
    "        index = tupel[0][0]\n",
    "        if index in index_count:\n",
    "            index_count[index].append(tupel)\n",
    "        else:\n",
    "            index_count[index] = [tupel]\n",
    "    for index, tupel_list in index_count.items():\n",
    "        if len(tupel_list[0]) == 2:\n",
    "            tupel1, tupel2 = tupel_list[0]\n",
    "            neue_tupel1 = tupel1[:-2] + (tupel2[-2], tupel2[-1])\n",
    "            neue_tupel2 = tupel2[:-2] + (tupel1[-2], tupel1[-1])\n",
    "            newlist.append(neue_tupel1)\n",
    "            newlist.append(neue_tupel2)\n",
    "\n",
    "    return newlist\n",
    "\n",
    "\n",
    "final_card = tausche_elemente(result_cardinality)\n",
    "print(final_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e283217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in one sentence maximal one relation --> limitation\n",
    "# cardinality with 2 or 3 not in available --> limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3f515b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['produkt', ['preis', 'produktname', 'produkt-id']], ['gebrauchtwaren', ['anzahl', 'vorbesitzer']], ['filiale', ['filialnamen', 'filialadresse', 'telefonnummer', 'filial-id']], ['verkauf', ['datum', 'uhrzeit', 'betrag']], ['mitarbeiter', ['mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer', 'mitarbeiter-id']], ['mitarbeiter', ['filialleiter', 'mitarbeiter-id']]]\n"
     ]
    }
   ],
   "source": [
    "# bring id into final_attr_list_ents (reason: assignement info for id to a specific entity)\n",
    "\n",
    "def extract_and_insert_id_words(list1, list2):\n",
    "    for word1 in list1:\n",
    "        for idx, sublist2 in enumerate(list2):\n",
    "            outer_word = sublist2[0]\n",
    "            inner_words = sublist2[1]\n",
    "            for word2 in inner_words:\n",
    "                if (word1.split('-')[0]) in outer_word:\n",
    "                    sublist2[1].append(word1)\n",
    "                    break\n",
    "    return list2\n",
    "\n",
    "result = extract_and_insert_id_words(final_pk, final_attr_list_ents)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe3eae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['produkt', ['produktname', 'preis', 'produkt-id']], ['gebrauchtwaren', ['vorbesitzer', 'anzahl']], ['filiale', ['filialnamen', 'filial-id', 'telefonnummer', 'filialadresse']], ['verkauf', ['betrag', 'datum', 'uhrzeit']], ['mitarbeiter', ['nachname', 'mitarbeiteradressen', 'mitarbeiter-id', 'mitarbeiternamen', 'filialleiter', 'vorname', 'telefonnummer']]]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from inner_words\n",
    "\n",
    "def merge_inner_words(list_data):\n",
    "    merged_data = {}\n",
    "    for outer_word, inner_words in list_data:\n",
    "        if outer_word in merged_data:\n",
    "            merged_data[outer_word].extend(inner_words)\n",
    "        else:\n",
    "            merged_data[outer_word] = inner_words\n",
    "\n",
    "    for outer_word, inner_words in merged_data.items():\n",
    "        merged_data[outer_word] = list(set(inner_words))\n",
    "\n",
    "    merged_list = [[outer_word, inner_words] for outer_word, inner_words in merged_data.items()]\n",
    "    return merged_list\n",
    "\n",
    "final_attr_and_id_list_ents = merge_inner_words(result)\n",
    "print(final_attr_and_id_list_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32cb5bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['verkauf', 'mitarbeiter', 'filiale', 'geschäft', 'produkt']\n",
      "--------------\n",
      "['filialleiter-id', 'filial-id', 'mitarbeiter-id', 'produkt-id']\n",
      "--------------\n",
      "['preis', 'produktname', 'anzahl', 'vorbesitzer', 'filialnamen', 'filialadresse', 'telefonnummer', 'datum', 'uhrzeit', 'betrag', 'mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer', 'filialleiter']\n",
      "--------------\n",
      "[['produkt', ['preis', 'produktname', 'produkt-id']], ['gebrauchtwaren', ['anzahl', 'vorbesitzer']], ['filiale', ['filialnamen', 'filialadresse', 'telefonnummer', 'filial-id']], ['verkauf', ['datum', 'uhrzeit', 'betrag']], ['mitarbeiter', ['mitarbeiternamen', 'vorname', 'nachname', 'mitarbeiteradressen', 'telefonnummer', 'mitarbeiter-id', 'filialleiter', 'mitarbeiter-id']], ['mitarbeiter', ['filialleiter', 'mitarbeiter-id']]]\n",
      "--------------\n",
      "[['produkt', ['produktname', 'preis', 'produkt-id']], ['gebrauchtwaren', ['vorbesitzer', 'anzahl']], ['filiale', ['filialnamen', 'filial-id', 'telefonnummer', 'filialadresse']], ['verkauf', ['betrag', 'datum', 'uhrzeit']], ['mitarbeiter', ['nachname', 'mitarbeiteradressen', 'mitarbeiter-id', 'mitarbeiternamen', 'filialleiter', 'vorname', 'telefonnummer']]]\n",
      "--------------\n",
      "[]\n",
      "--------------\n",
      "[[['geschäft', 'hat', 'filiale'], 0], [['filiale', 'bietet', 'produkt'], 4], [['filiale', 'beschäftigt', 'mitarbeiter'], 6], [['mitarbeiter', 'bearbeiten', 'verkauf'], 7], [['verkauf', 'involviert', 'produkt'], 8], [['produkttype', 'registriert', 'verpackungsnummer'], 10]]\n",
      "--------------\n",
      "[(0, 'Geschäft', None, 'Ein', 1, 'n'), (0, 'Filialen', 'hat', 'viele', 1, 1), (4, 'Filiale', None, 'Die', 1, 'n'), (4, 'Produkte', 'bietet', 'viele', 'n', 'm'), (6, 'Filiale', None, 'Die', 1, 'n'), (6, 'Mitarbeiter', 'beschäftigt', 'viele', 'n', 'm'), (7, 'Mitarbeiter', None, 'Ein', 0, 1), (7, 'Verkauf', 'höchstens', 'einen', 1, 1), (8, 'Im', 'Im', 'Verkauf', 1, 'n'), (8, 'Produkte', 'können', 'viele', 'n', 'm')]\n"
     ]
    }
   ],
   "source": [
    "print(final_ents)\n",
    "print(\"--------------\")\n",
    "print(final_pk)\n",
    "print(\"--------------\")\n",
    "print(final_attr_list)\n",
    "print(\"--------------\")\n",
    "print(final_attr_list_ents)\n",
    "print(\"--------------\")\n",
    "print(final_attr_and_id_list_ents)\n",
    "print(\"--------------\")\n",
    "print(final_isa_list)\n",
    "print(\"--------------\")\n",
    "print(index_list)\n",
    "print(\"--------------\")\n",
    "print(final_card)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b261fb25",
   "metadata": {},
   "source": [
    "### 4. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86431540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert entities into template\n",
    "\n",
    "template_json = '''\n",
    "{\n",
    "  \"projectVersion\": 1,\n",
    "  \"projectName\": \"notNamed\",\n",
    "  \"erContent\": {\n",
    "    \"drawBoardContent\": {\n",
    "      \"drawBoardElements\": [],\n",
    "      \"connections\": []\n",
    "    }\n",
    "  },\n",
    "  \"relContent\": {\n",
    "    \"drawBoardContent\": {\n",
    "      \"tables\": [],\n",
    "      \"connections\": []\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "string_list = final_ents\n",
    "\n",
    "def generate_unique_id(prefix):\n",
    "    return f\"{prefix}--{random.randint(1000000000000, 9999999999999)}\"\n",
    "\n",
    "data = json.loads(template_json)\n",
    "\n",
    "for name in string_list:\n",
    "    unique_id = generate_unique_id(\"StrongEntity\")\n",
    "    draw_board_element = {\n",
    "        \"id\": unique_id,\n",
    "        \"displayName\": name,\n",
    "        \"isHighlighted\": False,\n",
    "        \"isSelected\": False,\n",
    "        \"x\": 0,\n",
    "        \"y\": 0,\n",
    "        \"width\": 151.015625,\n",
    "        \"height\": 67,\n",
    "        \"objectType\": \"DrawBoardElement\",\n",
    "        \"erType\": \"StrongEntity\",\n",
    "        \"owningSide\": None\n",
    "    }\n",
    "    data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"].append(draw_board_element)\n",
    "\n",
    "filled_json = json.dumps(data, indent=2)\n",
    "\n",
    "final_output = \"../rule_based/output.json\"\n",
    "with open(final_output, \"w\") as file:\n",
    "    file.write(filled_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3244ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert attributes/id and attribute/id-connection to entity into template json file\n",
    "\n",
    "with open(final_output, 'r', encoding='UTF-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for inner_list in final_attr_and_id_list_ents:\n",
    "    entity_name, attributes = inner_list[0], inner_list[1]\n",
    "    if entity_name in final_ents:\n",
    "        for attribute_name in attributes:\n",
    "            if \"-id\" in attribute_name:\n",
    "                unique_id = generate_unique_id(\"IdentifyingAttribute\")\n",
    "                draw_board_element = {\n",
    "                \"id\": unique_id,\n",
    "                \"displayName\": attribute_name,\n",
    "                \"isHighlighted\": False,\n",
    "                \"isSelected\": False,\n",
    "                \"x\": 0,\n",
    "                \"y\": 0,\n",
    "                \"width\": 222,\n",
    "                \"height\": 70,\n",
    "                \"objectType\": \"DrawBoardElement\",\n",
    "                \"erType\": \"IdentifyingAttribute\",\n",
    "                \"owningSide\": None\n",
    "                }\n",
    "                data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"].append(draw_board_element)\n",
    "            else:\n",
    "                unique_id = generate_unique_id(\"NormalAttribute\")\n",
    "                draw_board_element = {\n",
    "                    \"id\": unique_id,\n",
    "                    \"displayName\": attribute_name,\n",
    "                    \"isHighlighted\": False,\n",
    "                    \"isSelected\": False,\n",
    "                    \"x\": 0,\n",
    "                    \"y\": 0,\n",
    "                    \"width\": 222,\n",
    "                    \"height\": 70,\n",
    "                    \"objectType\": \"DrawBoardElement\",\n",
    "                    \"erType\": \"NormalAttribute\",\n",
    "                    \"owningSide\": None\n",
    "                }\n",
    "                data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"].append(draw_board_element)\n",
    "\n",
    "            for existing_element in data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"]:\n",
    "                if existing_element[\"displayName\"] == entity_name:\n",
    "                    connection_id = generate_unique_id(\"Connection\")\n",
    "                    connection_block = {\n",
    "                        \"id\": f\"{unique_id} --> {existing_element['id']} - {connection_id}\",\n",
    "                        \"start\": unique_id,\n",
    "                        \"end\": existing_element['id'],\n",
    "                        \"min\": \"1\",\n",
    "                        \"max\": \"1\",\n",
    "                        \"objectType\": \"Connection\",\n",
    "                        \"isSelected\": False,\n",
    "                        \"withArrow\": False,\n",
    "                        \"withLabel\": False,\n",
    "                        \"connectionType\": \"AttributeConnector\",\n",
    "                        \"isHighlighted\": False\n",
    "                    }\n",
    "                    data[\"erContent\"][\"drawBoardContent\"][\"connections\"].append(connection_block)\n",
    "\n",
    "filled_json = json.dumps(data, indent=2)\n",
    "\n",
    "with open(final_output, \"w\") as file:\n",
    "    file.write(filled_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2e342cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitation: if entity has no id --> must correct it in editor tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d961ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'Geschäft', None, 'Ein', 1, 'n'), ['geschäft', 'hat', 'filiale']), ((0, 'Filialen', 'hat', 'viele', 1, 1), ['geschäft', 'hat', 'filiale']), ((4, 'Filiale', None, 'Die', 1, 'n'), ['filiale', 'bietet', 'produkt']), ((4, 'Produkte', 'bietet', 'viele', 'n', 'm'), ['filiale', 'bietet', 'produkt']), ((6, 'Filiale', None, 'Die', 1, 'n'), ['filiale', 'beschäftigt', 'mitarbeiter']), ((6, 'Mitarbeiter', 'beschäftigt', 'viele', 'n', 'm'), ['filiale', 'beschäftigt', 'mitarbeiter']), ((7, 'Mitarbeiter', None, 'Ein', 0, 1), ['mitarbeiter', 'bearbeiten', 'verkauf']), ((7, 'Verkauf', 'höchstens', 'einen', 1, 1), ['mitarbeiter', 'bearbeiten', 'verkauf']), ((8, 'Im', 'Im', 'Verkauf', 1, 'n'), ['verkauf', 'involviert', 'produkt']), ((8, 'Produkte', 'können', 'viele', 'n', 'm'), ['verkauf', 'involviert', 'produkt'])]\n"
     ]
    }
   ],
   "source": [
    "# prepare list for relations between entities (map cardinality to entities with relation)\n",
    "\n",
    "mapping_dict = {}\n",
    "\n",
    "for item in index_list:\n",
    "    key = item[1] \n",
    "    value = item[0]\n",
    "    mapping_dict[key] = value\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for tup in final_card:\n",
    "    key = tup[0] \n",
    "    value_from_dict = mapping_dict.get(key, None)\n",
    "    if value_from_dict is not None:\n",
    "        result_list.append((tup, value_from_dict))\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf7e6110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('geschäft', 'hat', '1', 'n'), ('filiale', 'hat', '1', '1'), ('filiale', 'bietet', '1', 'n'), ('produkt', 'bietet', 'n', 'm'), ('filiale', 'beschäftigt', '1', 'n'), ('mitarbeiter', 'beschäftigt', 'n', 'm'), ('mitarbeiter', 'bearbeiten', '0', '1'), ('verkauf', 'bearbeiten', '1', '1'), ('verkauf', 'involviert', '1', 'n'), ('produkt', 'involviert', 'n', 'm')]\n",
      "---------------------\n",
      "Entität 'geschäft': Beziehung = 'hat',  min = '1', max = 'n'\n",
      "Entität 'filiale': Beziehung = 'hat',  min = '1', max = '1'\n",
      "Entität 'filiale': Beziehung = 'bietet',  min = '1', max = 'n'\n",
      "Entität 'produkt': Beziehung = 'bietet',  min = 'n', max = 'm'\n",
      "Entität 'filiale': Beziehung = 'beschäftigt',  min = '1', max = 'n'\n",
      "Entität 'mitarbeiter': Beziehung = 'beschäftigt',  min = 'n', max = 'm'\n",
      "Entität 'mitarbeiter': Beziehung = 'bearbeiten',  min = '0', max = '1'\n",
      "Entität 'verkauf': Beziehung = 'bearbeiten',  min = '1', max = '1'\n",
      "Entität 'verkauf': Beziehung = 'involviert',  min = '1', max = 'n'\n",
      "Entität 'produkt': Beziehung = 'involviert',  min = 'n', max = 'm'\n"
     ]
    }
   ],
   "source": [
    "# created new list for adding relation to template\n",
    "\n",
    "extracted_info = []\n",
    "\n",
    "for index, tupel in enumerate(result_list):\n",
    "    inner_tupel, word_list = tupel\n",
    "    beziehung = word_list[1]\n",
    "    if index % 2 == 0:\n",
    "        wort = word_list[0]\n",
    "        info = (wort, beziehung, str(inner_tupel[-2]), str(inner_tupel[-1]))\n",
    "    else:\n",
    "        wort = word_list[2]\n",
    "        info = (wort, beziehung, str(inner_tupel[-2]), str(inner_tupel[-1]))\n",
    "        \n",
    "    extracted_info.append(info)\n",
    "\n",
    "print(extracted_info)\n",
    "print(\"---------------------\")\n",
    "for info in extracted_info:\n",
    "    print(f\"Entität '{info[0]}': Beziehung = '{info[1]}',  min = '{info[2]}', max = '{info[3]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c87331ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write relations into template\n",
    "\n",
    "with open(final_output, 'r', encoding='UTF-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def generate_unique_id2():\n",
    "    return f\"{random.randint(1000000000000, 9999999999999)}\"\n",
    "\n",
    "def create_strong_relations(json_data, relations_list):\n",
    "    for i, relation in enumerate(relations_list):\n",
    "        if i % 2 == 1: \n",
    "            display_name = relation[1]\n",
    "            unique_id = generate_unique_id(\"StrongRelation\")\n",
    "            strong_relation_element = {\n",
    "                \"id\": unique_id,\n",
    "                \"displayName\": display_name,\n",
    "                \"isHighlighted\": False,\n",
    "                \"isSelected\": False,\n",
    "                \"x\": 0,\n",
    "                \"y\": 0,\n",
    "                \"width\": 151.015625,\n",
    "                \"height\": 100.67708333333333,\n",
    "                \"objectType\": \"DrawBoardElement\",\n",
    "                \"erType\": \"StrongRelation\",\n",
    "                \"owningSide\": None\n",
    "            }\n",
    "            json_data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"].append(strong_relation_element)\n",
    "\n",
    "            # Search StrongEntity-Elements with the \"displayName\" to get their id in the template\n",
    "            for existing_element in data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"]:\n",
    "\n",
    "                if existing_element[\"displayName\"] == relation[0]:\n",
    "                    entity_id_1 = existing_element[\"id\"]\n",
    "                    connection_id_1 = generate_unique_id2()\n",
    "                    connection_block_1 = {\n",
    "                        \"id\": f\"{unique_id} --> {entity_id_1} - {connection_id_1}\",\n",
    "                        \"start\": unique_id,\n",
    "                        \"end\": entity_id_1,\n",
    "                        \"min\": relation[2],\n",
    "                        \"max\": relation[3],\n",
    "                        \"objectType\": \"Connection\",\n",
    "                        \"isSelected\": False,\n",
    "                        \"withArrow\": False,\n",
    "                        \"withLabel\": True,\n",
    "                        \"connectionType\": \"Association\",\n",
    "                        \"isHighlighted\": False\n",
    "                    }\n",
    "                    json_data[\"erContent\"][\"drawBoardContent\"][\"connections\"].append(connection_block_1)\n",
    "                    \n",
    "            for existing_element in data[\"erContent\"][\"drawBoardContent\"][\"drawBoardElements\"]:\n",
    "                if existing_element[\"displayName\"] == relations_list[i-1][0]:\n",
    "                    entity_id_2 = existing_element[\"id\"]\n",
    "                    connection_id_2 = generate_unique_id2()\n",
    "                    connection_block_2 = {\n",
    "                        \"id\": f\"{entity_id_2} --> {unique_id} - {connection_id_2}\",\n",
    "                        \"start\": entity_id_2,\n",
    "                        \"end\": unique_id,\n",
    "                        \"min\": relations_list[i-1][2],\n",
    "                        \"max\": relations_list[i-1][3],\n",
    "                        \"objectType\": \"Connection\",\n",
    "                        \"isSelected\": False,\n",
    "                        \"withArrow\": False,\n",
    "                        \"withLabel\": True,\n",
    "                        \"connectionType\": \"Association\",\n",
    "                        \"isHighlighted\": False\n",
    "                    }\n",
    "                    json_data[\"erContent\"][\"drawBoardContent\"][\"connections\"].append(connection_block_2)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "data = create_strong_relations(data, extracted_info)\n",
    "filled_json = json.dumps(data, indent=2)\n",
    "\n",
    "with open(final_output, \"w\") as file:\n",
    "    file.write(filled_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projektarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e04f4a2975c158b801cf0c8285a3912c4258c980c6fe7587b5ae35986cc1df98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
